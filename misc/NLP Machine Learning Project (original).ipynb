{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Data_cyb.json\", lines = True, orient = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "for i in df[\"annotation\"]:\n",
    "    rating.append(int(i[\"label\"][0]))\n",
    "    \n",
    "df[\"rating\"] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>extras</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0                             Get fucking real dude.   \n",
       "1   She is as dirty as they come  and that crook ...   \n",
       "2   why did you fuck it up. I could do it all day...   \n",
       "3   Dude they dont finish enclosing the fucking s...   \n",
       "4   WTF are you talking about Men? No men thats n...   \n",
       "\n",
       "                      annotation  extras  rating  \n",
       "0  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "1  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "2  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "3  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "4  {'notes': '', 'label': ['1']}     NaN       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>That is someone who does it from their heart. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Absolutely applaud your work to secure freedom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>You'll never learn it till you actually live i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Nothing on the reinstatement of federal Capito...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>Crickets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  rating\n",
       "96   That is someone who does it from their heart. ...       1\n",
       "97   Absolutely applaud your work to secure freedom...       0\n",
       "98   You'll never learn it till you actually live i...       1\n",
       "99   Nothing on the reinstatement of federal Capito...       1\n",
       "100                                           Crickets       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"Test_Twitter_Comments.csv\")\n",
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = df[[\"content\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([new_df1,tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(new_df[\"content\"], new_df[\"rating\"], train_size = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(X)\n",
    "reviews_test_clean = preprocess_reviews(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "Logistic regression model with just the removal of negligible symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6659619450317125\n",
      "Accuracy for C=0.05: 0.7032707374704639\n",
      "Accuracy for C=0.25: 0.7510259917920656\n",
      "Accuracy for C=0.5: 0.7693073000870538\n",
      "Accuracy for C=1: 0.7829871906479293\n"
     ]
    }
   ],
   "source": [
    "baseline_vectorizer = CountVectorizer(binary=True)\n",
    "baseline_vectorizer.fit(reviews_train_clean)\n",
    "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
    "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_baseline, y, train_size = 0.5\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.664511315593136\n",
      "Accuracy for C=0.05: 0.7177319074857\n",
      "Accuracy for C=0.25: 0.7637403630937578\n",
      "Accuracy for C=0.5: 0.7938323800049739\n",
      "Accuracy for C=1: 0.8117383735389206\n"
     ]
    }
   ],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(no_stop_words_train)\n",
    "X = cv.transform(no_stop_words_train)\n",
    "X_test = cv.transform(no_stop_words_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6779408107435961\n",
      "Accuracy for C=0.05: 0.7100223824919174\n",
      "Accuracy for C=0.25: 0.7582690872917185\n",
      "Accuracy for C=0.5: 0.7784133300174086\n",
      "Accuracy for C=1: 0.7913454364585923\n"
     ]
    }
   ],
   "source": [
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(stemmed_reviews_train)\n",
    "X = cv.transform(stemmed_reviews_train)\n",
    "X_test = cv.transform(stemmed_reviews_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6739617010693857\n",
      "Accuracy for C=0.05: 0.7232031832877394\n",
      "Accuracy for C=0.25: 0.7736881372792838\n",
      "Accuracy for C=0.5: 0.7963193235513554\n",
      "Accuracy for C=1: 0.8134792340213877\n"
     ]
    }
   ],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(lemmatized_reviews_train)\n",
    "X = cv.transform(lemmatized_reviews_train)\n",
    "X_test = cv.transform(lemmatized_reviews_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7224571002238249\n",
      "Accuracy for C=0.05: 0.8291469783635912\n",
      "Accuracy for C=0.25: 0.8744093509077344\n",
      "Accuracy for C=0.5: 0.8749067396170107\n",
      "Accuracy for C=1: 0.8756528226809251\n",
      "Final Accuracy: 0.9196717234518776\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_ngram = LogisticRegression(C=1)\n",
    "final_ngram.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6732156180054713\n",
      "Accuracy for C=0.05: 0.714250186520766\n",
      "Accuracy for C=0.25: 0.769211638895797\n",
      "Accuracy for C=0.5: 0.7968167122606317\n",
      "Accuracy for C=1: 0.8147227057945785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train_clean)\n",
    "X = wc_vectorizer.transform(reviews_train_clean)\n",
    "X_test = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75, \n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6234767470778413\n",
      "Accuracy for C=0.05: 0.6600348172096493\n",
      "Accuracy for C=0.25: 0.7324048744093509\n",
      "Accuracy for C=0.5: 0.7565282268092515\n",
      "Accuracy for C=1: 0.7811489679184282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.818950509823427\n",
      "Accuracy for C=0.05: 0.8696841581696095\n",
      "Accuracy for C=0.25: 0.8699328525242477\n",
      "Accuracy for C=0.5: 0.8681919920417807\n",
      "Accuracy for C=1: 0.8612285501119125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8957970654066153\n"
     ]
    }
   ],
   "source": [
    "final_svm_ngram = LinearSVC(C=0.05)\n",
    "final_svm_ngram.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8530216364088535\n",
      "Accuracy for C=0.05: 0.8756528226809251\n",
      "Accuracy for C=0.25: 0.8699328525242477\n",
      "Accuracy for C=0.5: 0.865456354140761\n",
      "Accuracy for C=1: 0.8624720218851032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9089778662024373\n"
     ]
    }
   ],
   "source": [
    "final_svm_ngram = LinearSVC(C=0.05)\n",
    "final_svm_ngram.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"./final_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "\n",
    "# Load in user_data.csv from S3 into a DataFrame\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"CsvReader\").getOrCreate()\n",
    "spark_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r\"./final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark_df = spark_df.withColumn(\"rating1\", spark_df[\"rating\"].cast(IntegerType()))\n",
    "spark_df = spark_df.drop(spark_df.rating)\n",
    "spark_df = spark_df.withColumnRenamed(\"rating1\", \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, review_text: string, review_length: int]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, length\n",
    "review_df = spark_df.withColumnRenamed(\"rating\", \"label\")\\\n",
    "      .withColumnRenamed(\"content\", \"review_text\")\\\n",
    "      .select([\"label\", \"review_text\"])\n",
    "review_df = review_df.withColumn('review_length', length(review_df['review_text'])).dropna()\n",
    "review_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "\n",
    "# Create all the features to the data set\n",
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'review_length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the pipeline\n",
    "cleaner = data_prep_pipeline.fit(review_df)\n",
    "cleaned = cleaner.transform(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break data down into a training set and a testing set\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Naive Bayes model and fit training data\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|         review_text|review_length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|   Santa is Itali...|           67|[, , , santa, is,...|[, , , santa, ita...|(262144,[15889,23...|(262144,[15889,23...|(262145,[15889,23...|[-799.45127258973...|[0.99999999999995...|       0.0|\n",
      "|    0|  (: ahaha hii ce...|           22|[, , (:, ahaha, h...|[, , (:, ahaha, h...|(262144,[111315,1...|(262144,[111315,1...|(262145,[111315,1...|[-419.39507938371...|[0.93244733609704...|       0.0|\n",
      "|    0|  - Marryyyyy!!!!...|          102|[, , -, marryyyyy...|[, , -, marryyyyy...|(262144,[24417,32...|(262144,[24417,32...|(262145,[24417,32...|[-1495.1293916410...|[1.0,3.5619912989...|       0.0|\n",
      "|    0|                   .|            3|             [, , .]|             [, , .]|(262144,[1536,249...|(262144,[1536,249...|(262145,[1536,249...|[-56.655135656949...|[0.97532235105766...|       0.0|\n",
      "|    0|                   .|            3|             [, , .]|             [, , .]|(262144,[1536,249...|(262144,[1536,249...|(262145,[1536,249...|[-56.655135656949...|[0.97532235105766...|       0.0|\n",
      "+-----+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting reviews was: 0.811625\n"
     ]
    }
   ],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.04: 0.8176843676159682\n",
      "Accuracy for C=0.05: 0.8179330928988932\n",
      "Accuracy for C=0.06: 0.8188036313891307\n",
      "Accuracy for C=0.07: 0.8201716204452183\n",
      "Accuracy for C=0.08: 0.8183061808232807\n",
      "Accuracy for C=0.09: 0.8178087302574306\n",
      "Accuracy for C=0.1: 0.8166894664842681\n",
      "Accuracy for C=0.11: 0.8150727521452555\n",
      "Accuracy for C=0.12: 0.8148240268623306\n",
      "Accuracy for C=0.13: 0.814699664220868\n",
      "Accuracy for C=0.14: 0.813953488372093\n",
      "Accuracy for C=0.15: 0.8135804004477055\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.5\n",
    ")\n",
    "\n",
    "ccc = []\n",
    "c_scores = []\n",
    "\n",
    "for c in [0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    ccc.append(c)\n",
    "    c_scores.append(accuracy_score(y_val, svm.predict(X_val)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU1fnH8c+TPYQkQBLWkARI2BeRACKgKFaBKmrdQFFxww1tf67Yan/W2kWrrfoDbdEqllYBd1xBEC0BFILIviQghLAmYU0ihCTP748Z2hgCGZJJ7izP+/XKi5k7Z26e09j7nXPumXtFVTHGGBN8QpwuwBhjjDMsAIwxJkhZABhjTJCyADDGmCBlAWCMMUEqzOkCTkdiYqKmpaU5XYYxxviV5cuXF6pqUvXtfhUAaWlpZGdnO12GMcb4FRHZVtN2mwIyxpggZQFgjDFBygLAGGOClAWAMcYEKQsAY4wJUhYAxhgTpCwAjDEmSFkAmNOyeHMhG3YfcroMY4wXWAAYj63fdYgbX13Kra9nc6yi0ulyjDH1ZAFgPFJWXsn9s1YSGiLk7/+B977d4XRJxph68igARGSEiGwUkVwRmVTD6ykiskBEVojIKhEZ5d7+ExFZLiKr3f+eX+U9/dzbc0XkBRER73XLeNvkBbms23WI58f0pXdyPJMX5NoowBg/V2sAiEgoMAUYCXQHxopI92rNHgVmqWpfYAzwont7IXCJqvYCbgSmV3nPS8AEIMP9M6Ie/TANaM2Og0xZkMvlfdtxUY/W3Ht+Bnn7Svngu51Ol2aMqQdPRgADgFxV3aKqZcAM4NJqbRSIcz+OB3YCqOoKVT1+lFgLRIlIpIi0AeJUdYm6bkr8D+CyevbFNICj5RXcN+s7EmIiePySHgAM79aSHm3jmPxFDuU2CjDGb3kSAO2A7VWe57u3VfU4ME5E8oFPgHtq2M8VwApVPep+f34t+wRARCaISLaIZBcUFHhQrvGm5+blsGlPMU9d0Zv4JuEAiAj3Ds9ga1Eps1faKMAYf+VJANQ0N6/Vno8FpqlqMjAKmC4i/9m3iPQAngJuP419ujaqTlXVTFXNTEo64XLWpgGtyNvP377azNWZyZzXteWPXruweyu6tYlj8he5VFTW+Kczxvg4TwIgH2hf5Xky7imeKm4BZgGo6hIgCkgEEJFk4D3gBlXdXGWfybXs0zjoyLEK7n9rJa3jonj04uqnfNyjgPPT2VJYwker7E9njD/yJACWARki0kFEInCd5J1drU0eMBxARLrhCoACEWkGfAw8oqqLjjdW1V3AYRE5y7365wbgg3r3xnjNM3M2sqWghKeu7E1cVHiNbS7q0ZourWJ5YX6OjQKM8UO1BoCqlgMTgTnAelyrfdaKyBMiMtrd7H7gNhFZCbwJjHef3J0IpAOPich37p/jcwl3Aq8AucBm4FNvdszU3bKt+/j7ou+5bmAKQzNOPu0WEiLcMzydzQUlfLJ6VyNWaIzxBnEdp/1DZmam2i0hG1ZpWTkjn19IRaUy5xfnEBN56ruGVlYqFz33b0Tgs5+fQ0iIfZ3DGF8jIstVNbP6dvsmsPmRpz7dwLaiUv50ZZ9aD/5wfBSQwaY9xXy2dncjVGiM8RYLAPMfizcX8vqSbYw/O41BnRI8ft9Pe7WhU1IML8zPodLOBRjjNywADADFR8t56O1VpCU04eERXU/rvaEhwj3nZ7Bh92HmrrNRgDH+wgLAAPC7j9ez48APPHNVH6IjQk/7/Rf3bkOHxBien5+LP51XMiaYWQAY/r2pgDeX5nHb0I5kprWo0z7CQkOYeF4663cd4vN1e7xcoTGmIVgABLmDPxzj4XdWkd6yKff9pHO99nXpGW1JTWjC8/NzbBRgjB+wAAhyT360jr2Hj/LsVX2ICj/9qZ+qwkJDuPu8dNbuPMQXG/Z6qUJjTEOxAAhi89fv4a3l+dxxbkf6tG/mlX1e3rcd7VtE2yjAGD9gARCkDpSWMend1XRtHcu9wzO8tt/w0BDuHpbOqvyDfLnJrt5qjC+zAAhSj89ey/6SMp65qg+RYfWb+qnuZ2cm065ZNM/Ps1GAMb7MAiAIfbZmN+9/t5OJ56fTs1281/cfEeY6F/Dd9gP8O6fQ6/s3xniHBUCQKSo+yq/eW03PdnHcfV56g/2eK/sl0zY+iufnbbJRgDE+ygIgyPz6g7UcOnKMZ686g/DQhvvzR4SFcOd56Xybd4BFuUUN9nuMMXVnARBEPly5k49X7+IXF3SmS+vYBv99V2cm0zouiufn2yjAGF9kARAk9h4+wmMfrKFP+2bcfk7HRvmdkWGh3DmsE8u27mfJFhsFGONrLACCgKryq/fWUFpWwbNX9SGsAad+qrumf3taxkby/LycRvudxhjPWAAEgfdW7ODzdXt48MIupLds2qi/Oyo8lDvO7cQ33+/jaxsFGONTLAAC3O6DR/jf2WvJTG3OzUM6OFLDtQNTSGwayQvzbRRgjC+xAAhgqsqkd1dxrKKSZ67qQ6hDt2t0jQI6snhzEcu27nOkBmPMiSwAAtis7O18ubGASSO6kpYY42gt1w1MJbFphI0CjPEhFgABaseBH/jtR+sZ1DGBGwalOV0O0RGhTDinIwtzClm+bb/T5Rhj8DAARGSEiGwUkVwRmVTD6ykiskBEVojIKhEZ5d6e4N5eLCKTq73nGnfbtSLytHe6Y8A19fPw26tQVZ6+sjchDk39VDfurFRaxETwvI0CjPEJtQaAiIQCU4CRQHdgrIh0r9bsUWCWqvYFxgAvurcfAR4DHqi2zwTgT8BwVe0BtBKR4fXpiPmvf36TR1ZuIb/8aTfat2jidDn/0SQijNuGduTfmwpYkWejAGOc5skIYACQq6pbVLUMmAFcWq2NAnHux/HATgBVLVHVLFxBUFVHYJOqHr9e8DzgijrUb6rJKyrlD5+sZ2hGItcOSHG6nBNcPyiVZk3C7VyAMT7AkwBoB2yv8jzfva2qx4FxIpIPfALcU8s+c4GuIpImImHAZUD7mhqKyAQRyRaR7IICu778qVRWKg++vZJQEZ66ojcivjH1U1XTSNcoYMHGAlblH3C6HGOCmicBUNNRpPqFXcYC01Q1GRgFTBeRk+5bVfcDdwIzgYXAVqD8JG2nqmqmqmYmJSV5UG7wmrZ4K998v4/HLulO22bRTpdzUjcMSiU+2kYBxjjNkwDI58efzpNxT/FUcQswC0BVlwBRQOKpdqqqH6rqQFUdBGwE7GhQD1sKinl6zgaGd23JVf2SnS7nlGKjwrllSAfmrd/Lmh0HnS7HmKDlSQAsAzJEpIOIROA6yTu7Wps8YDiAiHTDFQCnnK8RkZbuf5sDdwGvnF7p5riKSuWBt1YSGRbK73/WyyenfqobPziN2KgwGwUY46BaA0BVy4GJwBxgPa7VPmtF5AkRGe1udj9wm4isBN4Exqv7+r8ishX4MzBeRPKrrCB6XkTWAYuAP6rqJm92LJi8snAL3+Yd4Deje9AqLsrpcjwSFxXOzYM7MHfdHtbtPOR0OcYEJfGn67RnZmZqdna202X4lI27D3PJ5CzO65LEX8f184tP/8cdLD3GkKe+YHB6In+9vp/T5RgTsERkuapmVt9u3wT2Y+t3HeK6V74hLiqM313uH1M/VcU3CeemwWl8tnY3G3bbKMCYxmYB4KdW5O1nzNSvCQsRZkw4i8SmkU6XVCc3D+lA08gw/m9+rtOlGBN0LAD80OLNhYx75Rvio8N5645BpLds+Ns7NpRmTSK48exUPlmzi017DjtdjjFBxQLAz8xfv4fxry2jbbNo3rpjkE9d6qGubhnSkejwUP7vCxsFGNOYLAD8yIcrd3L79OV0bR3LzNsH+c2Kn9q0iInghkFpfLRqJ7l7bRRgTGOxAPATby7N494ZKzgztTn/unUgLWIinC7Jq24b2oGosFAm2yjAmEZjAeAHXlm4hUfeXc05GUm8ftMAYqPCnS7J6xKaRnL9oFRmr9zJloJip8sxJihYAPgwVeUvn2/iyY/X89NebXj5hkyiI0KdLqvB3Da0IxFhITYKMKaRWAD4KFXltx+t5/n5OVzVL5kXxvYlIiyw/1xJsZGMG5jK+9/tYGthidPlGBPwAvuI4qcqKpVJ76zm1UXfc9PgNJ66ordjN3RvbBPO7Uh4aAiTF9gowJiGZgHgY8rKK7l3xgpmZm/n3uEZ/Pri7j5zS8fG0DI2imsHpvDeih3kFZU6XY4xAc0CwIccOVbB7dOz+XjVLn45qiv3/aSz313ewRvuOLcToSHCFBsFGNOgLAB8xOEjx7jx1aV8uamA31/eiwnndHK6JMe0iotibP/2vPNtPtv32SjAmIZiAeAD9peUMe6Vb1i+bT/PXXMG1w70vXv5NrY7hnUiRIQXv9zsdCnGBCwLAIftPXSEMVO/Zv3uw/x1XD8uPaP67ZaDU5v4aK7un8zby7ezcrvdO9iYhmAB4KDt+0q56m9L2L6/lGnj+3NB91ZOl+RT7hqWTlxUOJdOWcQvZqyw6SBjvMwCwCGbC4q5+m9L2F9Sxj9vHcjZ6ae8hXJQatssmi8eGMadwzrx6ZrdnP/sl/zmw7XsKylzujRjAoLdEcwBa3ce5Ia/L0UEpt8ykG5t4pwuyeftPniE5+ZtYlb2dppEhHHHuR25eUgHmkSEOV2aMT7vZHcEswBoZMu37WP8a8uIjQzjn7cOpGNSU6dL8iu5ew/z9GcbmbtuD0mxkfziggyuzmxPeKgNZo05GbslpA/Iyilk3CtLSWwayVt3nm0H/zpIbxnL1BsyeefOQaS2aMKv3lvDRX/5N5+u3oU/fZgxxhdYADSSuWt3c/O0ZaQmNGHW7YNo1yza6ZL8Wr/UFrx1xyBeuSGT0BDhzn99y2UvLubrLUVOl2aM3/AoAERkhIhsFJFcEZlUw+spIrJARFaIyCoRGeXenuDeXiwik6u9Z6yIrHa3/0xEAvYs6PsrdnDnv76le9s4Zk4YRFKsf96/19eICBd0b8VnvziHp6/s/Z8ltTe9tpT1u+wm88bUptZzACISCmwCfgLkA8uAsaq6rkqbqcAKVX1JRLoDn6hqmojEAH2BnkBPVZ3obh8G7AS6q2qhiDwNlKrq46eqxR/PAfzz62089sEazuqQwMs3ZtI00k5aNpQjxyqYtngrLy7I5fDRci7v2477ftKZ5Ob+f9tMY+qjPucABgC5qrpFVcuAGcCl1doocHwpSzyugzuqWqKqWcCR6vW4f2LEdbGbuOPvCSR//Wozj76/huFdW/LaTf3t4N/AosJDuePcTix86HwmnNORj1bt4vxnvuLJj9ax35aOGnMCTwKgHbC9yvN897aqHgfGiUg+8Alwz6l2qKrHgDuB1bhHAsDfa2orIhNEJFtEsgsKCjwo13mqyp/mbOCPn25gdJ+2vDSuH1HhgXsjF18T3yScR0Z248sHhnFZ37a8uuh7znl6AVMW5PJDWYXT5RnjMzwJgJouR1l93mgsME1Vk4FRwHQROem+RSQcVwD0BdoCq4BHamqrqlNVNVNVM5OSkjwo11m7Dv7AYx+sYcqCzYwd0J6/XHOGLVF0SNtm0Tx9ZR8+/fk5DOzYgj/N2ciwZxbw5tI8yisqnS7PGMd5MieRD7Sv8jyZE6drbgFGAKjqEhGJAhKBvSfZ5xnutpsBRGQWcMLJZX9QfLScrzcXkZVbyMKcAjYXuO5kNeGcjjwysmtQXs7Z13RpHcsrN/Zn6ff7+OOn63nk3dW8snALD43oyoXdW9nfyAQtTwJgGZAhIh2AHcAY4NpqbfKA4cA0EekGRAGnmq/ZAXQXkSRVLcB1gnn96RbvhPKKSlbmHyQrp5Cs3AJW5B2gvFKJCg9hYIcExg5IYWhGEl1axzpdqqlmQIcWvHPn2cxdt4enP9vA7dOXc2ZKMyaN7MaADi2cLs+YRufRN4HdyzqfA0KBV1X1dyLyBJCtqrPdK39eBprimh56SFXnut+7FddJ3gjgAHChqq4TkTuAnwPHgG3AeFU95SJuJ1YBqSpbi0rJyilgYU4hS7YUcfhIOSLQq108Q9ITGZKRSL/U5kSG2Ty/vyivqOTt5fn8Zd4m9hw6ygXdWvLQiK50bmXBbQKPXQriNOwvKWPR5kKycgpZmFPIjgM/ANCuWTRDMxIZmpHE2Z0SaB4T0eC1mIb1Q1kFry3+npe+3EzJ0XLGDEjhidE9CLPzNiaAnCwAbF0icLS8guVb97Mw13XQX7PzIKoQGxnGoE4J3HFuR4ZkJJGW0MTmiwNMdEQodw1LZ2z/FJ6fn8O0xVuJDAvhfy/p4XRpxjS4oAwAVWXD7sOuT/i5hSz9vogjxyoJCxH6pjTjF8M7MyQjkT7J8fZJMEg0j4ng8dE9EIHXFm2la+tYrulvd2YzgS1oAmDPoSMszCkkK6eArNwiCouPAtApKYYx/VMYkp7IWZ0S7MtaQe5Xo7qRu7eYR99fQ8ekpvRPs5PDJnAFxTmAK19aTPa2/QAkxEQw2H3idkh6Im3tomymmoOlx7j8xUUc/OEYH0wcbJeSMH4vqE8CPz8vh6jwEIZkJNKtdRwhITaPb05tc0Exl01ZRLtm0bxz59nE2MjQ+LGgvh/Azy/I4PZzO9Gjbbwd/I1HOiU1ZfK1Z7Jpz2Hum/UdlZX+80HJGE8FRQAYUxfndk7il6O6MWftHp6bt8npcozxOhvXGnMKtwzpwMbdh3nhi1w6t47l4t5tnS7JGK+xEYAxpyAiPHl5T/qlNueBt1ayZsdBp0syxmssAIypRWRYKH8d148WTSK47R/Z7D1c/fYWxvgnCwBjPJAUG8nLN2ZyoPQYt09fzpFjdl8B4/8sAIzxUI+28fz56j6syDvAL99bjT8toTamJhYAxpyGkb3a8IsLMnj32x28vHCL0+UYUy8WAMacpnvPz2BUr9b84dMNLNhwsnseGeP7LACMOU0hIcIzV/WhW+s47n1zBbl7DztdkjF1YgFgTB00iQjj5RsziQwP4ZbXszlQWuZ0ScacNgsAY+qoXbNo/nZ9P3YdOMLdb3zLMbvRvPEzFgDG1EO/1Bb8/me9WJRbxJMfrXO6HGNOi10Kwph6urJfMht3H+Llhd/TpXUc1w60G8kY/2AjAGO8YNLIbgzrksSvP1jD11uKnC7HGI9YABjjBaEhwgtj+5Ka0IQ7/7mc7ftKnS7JmFp5FAAiMkJENopIrohMquH1FBFZICIrRGSViIxyb09wby8WkclV2seKyHdVfgpF5DnvdcuYxhcXFc4rN/anUuHW17MpPlrudEnGnFKtASAiocAUYCTQHRgrIt2rNXsUmKWqfYExwIvu7UeAx4AHqjZW1cOqesbxH2Ab8G69emKMD+iQGMOUa88kt6CY/5lpN5Ixvs2TEcAAIFdVt6hqGTADuLRaGwXi3I/jgZ0Aqlqiqlm4gqBGIpIBtAQWnmbtxvikIRmJPPbTbny+bg/Pfr7R6XKMOSlPVgG1A7ZXeZ4PDKzW5nFgrojcA8QAF5xGDWOBmXqSK2uJyARgAkBKiq2uMP7hxrPT2LjnMFMWbKZzq1guPaOd0yUZcwJPRgA13US3+sF6LDBNVZOBUcB0EfH0BPMY4M2TvaiqU1U1U1Uzk5KSPNylMc4SEX4zuicDOrTgobdXsXL7AadLMuYEnhyk84H2VZ4n457iqeIWYBaAqi4BooDE2nYsIn2AMFVd7lG1xviRiLAQXrruTJJiI5kwPZs9h+xGMsa3eBIAy4AMEekgIhG4PrHPrtYmDxgOICLdcAVAgQf7HsspPv0b4+8Smkby8g2ZHD5SzgS7kYzxMbUGgKqWAxOBOcB6XKt91orIEyIy2t3sfuA2EVmJ64A+/vicvohsBf4MjBeR/GoriK7GAsAEuG5t4vjLNWewcvsBJr2zym4kY3yG+NN/jJmZmZqdne10GcbUyeQvcnhm7iYmjezKHed2crocE0REZLmqZlbfbtcCMqaR3H1eOhv3FPPUZxvIaNmU4d1aOV2SCXJ2KQhjGomI8PQVvenZNp6fz/iOTXvsRjLGWRYAxjSi6IhQXr4hk+iIUG59PZv9JXYjGeMcCwBjGlnr+CimXt+P3YeO8ODbq5wuxwQxCwBjHNA3pTn3/aQz89bvYWGOJyumjfE+CwBjHHLT4DRSWjThyY/WU263kzQOsAAwxiGRYaH8clQ3Nu45zIxl22t/gzFeZgFgjIMu6tGKszq24M+fb+LgD8ecLscEGQsAYxwkIjx2cXf2l5bxf/NznC7HBBkLAGMc1qNtPNdktmfa4q1sKSh2uhwTRCwAjPEB91/YhajwUH7/yQanSzFBxALAGB+QFBvJ3eelM2/9HrJyCp0uxwQJCwBjfMRNg9No3yKa3360zpaFmkZhAWCMj4gKD+WXI13LQmdm27JQ0/AsAIzxISN6tmZghxY8O3cTh47YslDTsCwAjPEhVZeFTv4i1+lyTICzADDGx/RsF8/V/drz2qLv2VpY4nQ5JoBZABjjg+6/qDMRoSH87pP1TpdiApgFgDE+qGVsFHefn87n6/awKNeWhZqGYQFgjI+6eXAHkpu7loVWVPrPvbuN/7AAMMZHRYW7rha6YfdhZtrVQk0D8CgARGSEiGwUkVwRmVTD6ykiskBEVojIKhEZ5d6e4N5eLCKTq70nQkSmisgmEdkgIld4p0vGBI6RPVszIK0Fz87daMtCjdfVGgAiEgpMAUYC3YGxItK9WrNHgVmq2hcYA7zo3n4EeAx4oIZd/wrYq6qd3fv9qk49MCaAHV8Wuq+0jCm2LNR4mScjgAFArqpuUdUyYAZwabU2CsS5H8cDOwFUtURVs3AFQXU3A39wt6tUVTvTZUwNeiXHc+WZybxqy0KNl3kSAO2AqhOQ+e5tVT0OjBORfOAT4J5T7VBEmrkf/lZEvhWRt0Sk1UnaThCRbBHJLiiwe6ea4PTgRV2ICA3hD5/aslDjPZ4EgNSwrfqShLHANFVNBkYB00XkVPsOA5KBRap6JrAEeKamhqo6VVUzVTUzKSnJg3KNCTwt46K467x05qzdw+LNNlg23uFJAOQD7as8T8Y9xVPFLcAsAFVdAkQBiafYZxFQCrznfv4WcKYHtRgTtG4Z0oF2zaL57UfrbVmo8QpPAmAZkCEiHUQkAtdJ3tnV2uQBwwFEpBuuADjpfI2qKvAhMMy9aTiw7rQqNybIHF8Wun7XIWbZ1UKNF9QaAKpaDkwE5gDrca32WSsiT4jIaHez+4HbRGQl8CYw3n2QR0S2An8GxotIfpUVRA8Dj4vIKuB69z6MMacwqldr+qc155k5tizU1J+4j9N+ITMzU7Ozs50uwxhHrc4/yOgpWUw4pyOPjOzmdDnGD4jIclXNrL7dvglsjJ/plRzPFWcm81rWVrYV2bJQU3cWAMb4oQcv6kJYqPAHu4m8qQcLAGP8UKu4KO4a1onP1u5myeYip8sxfsoCwBg/devQju5loXa1UFM3FgDG+Kmo8FAmjezKul2HeHu5LQs1p88CwBg/dnHvNvRLbc6f5mzksC0LNafJAsAYPyYi/Pri7hQWlzFlwWanyzF+xgLAGD/Xp30zrjgzmVezvievqNTpcowfsQAwJgA8NKILoSFiVws1p8UCwJgAcHxZ6KdrdvP1FlsWajxjAWBMgLjtnI60jY+yZaHGYxYAxgSIqPBQJo3qxtqdh3hneb7T5Rg/YAFgTAC5pHcbzkxpxtNzNlJ8tNzpcoyPswAwJoCICL++pAeFxUd5cYHdRN6cmgWAMQHmjPbN+FnfdryS9T3b99myUHNyFgDGBKAHR3QhVGxZqDk1CwBjAlCb+GjuOLcTn6zezTe2LNSchAWAMQFqgntZ6BO2LNSchAWAMQEqOiKUh0d2dS0L/daWhZoTWQAYE8BG92lL35Rm/MmWhZoaWAAYE8COXy204PBRXvrSloWaH/MoAERkhIhsFJFcEZlUw+spIrJARFaIyCoRGeXenuDeXiwik6u950v3Pr9z/7T0TpeMMVX1TWnO5X3b8fLC75m5LI9dB39wuiTjI8JqayAiocAU4CdAPrBMRGar6roqzR4FZqnqSyLSHfgESAOOAI8BPd0/1V2nqtn164IxpjYPjejC8m37efid1QB0SophaEYSQ9ITOatTAk0jaz0UmADkyV99AJCrqlsARGQGcClQNQAUiHM/jgd2AqhqCZAlIuleq9gYc9raxEfz1YPD2LjnMFk5hSzMKWTGsjymLd5KWIjQN6UZQ9KTGJKRSJ/keMJCbXY4GHgSAO2AqjcczQcGVmvzODBXRO4BYoALPPz9r4lIBfAO8KSqnrBWTUQmABMAUlJSPNytMaY6EaFr6zi6to7j1qEdOVpewfKt+1mYW0hWTiHPzd/EX+ZtIjYqjEEdExiakciQjCTSEpogIk6XbxqAJwFQ01+++oF6LDBNVZ8VkUHAdBHpqaqVp9jvdaq6Q0RicQXA9cA/TvhFqlOBqQCZmZm2mNkYL4kMC+Xs9ETOTk/k4RGwv6SMRZsL/zNCmLtuDwDtmkW7wyCRwZ0SaR4T4XDlxls8CYB8oH2V58m4p3iquAUYAaCqS0QkCkgE9p5sp6q6w/3vYRF5A9dU0wkBYIxpHM1jIri4d1su7t0WVWVrUSlZOQUszCnk41W7mLFsOyLQs208QzISGZqeSL+05kSGhTpduqkjTwJgGZAhIh2AHcAY4NpqbfKA4cA0EekGRAEFJ9uhiIQBzVS1UETCgYuBeXWo3xjTAESEDokxdEiM4fpBaZRXVLIy/yBZOYVk5Rbw8r+38NKXm4kKD2FAhwSGpicytHMiXVrF2nSRH5Eapt1PbORa1vkcEAq8qqq/E5EngGxVne1e+fMy0BTX9NBDqjrX/d6tuE4QRwAHgAuBbcC/gXD3PucB96lqxanqyMzM1OxsWzRkjNOKj5bz9eYisnILWZhTwOaCEgASm0YyJD2BIRlJnNWxBW3jowkJsUBwmogsV9XME7Z7EgC+wgLAGN+088APZLlPJi/KLaSopAyAiLAQ2jePJjUhhpQWTf77k+D6Nyrcpo8agwWAMaZRVFYq63cfYkXeAfL2lZJXVMq2faXkFZVQUvbjQX7L2EhSE5rQvkUTUlvE/PdxQhMSYr7XI5IAAAt2SURBVCJsOslLThYA9u0PY4xXhYQIPdrG06Nt/I+2qyr7SspcoVA1GPaVsji3iHcP7fhR+5iIUNq7RwypCcdHDq6RRLtm0USE2XcV6ssCwBjTKESEhKaRJDSNpG9K8xNeP3Ksgvz9rkDYVvTfkNhSWMJXmwo4Wv7fVeUh4vpy23+DoQkXdGtF51axjdklv2dTQMYYn1dZqew9fNQdDiVs3/ff0UNeUSlFJWVEhoXwxyt6cXnfZKfL9Tk2BWSM8VshIULr+Chax0cxoEOLE17fe+gIE99cwf/MXMnaHYeYNLKrXc7CA/a/kDHG77WMi+Jftw7khkGpvJL1PTdNW8aB0jKny/J5FgDGmIAQHhrCE5f25KkrevH1liJGT17Ext2HnS7Lp1kAGGMCyjX9U5gxYRA/HKvg8hcX8dmaXU6X5LMsAIwxAadfanM+nDiEjFax3PHPb/nz55uorPSfBS+NxQLAGBOQWsdHMXPCWVzZL5kX5ucwYfpyDh855nRZPsUCwBgTsKLCQ/nTlb3530u6s2DjXi5/cTHfF5Y4XZbPsAAwxgQ0EeGmwR2YfvMAioqPcunkLL7ceNIr1QcVCwBjTFA4Oz2R2ROH0LZZNDdPW8Zfv9qMP30RtiFYABhjgkb7Fk14966zGdmrDX/8dAM/n/EdP5Sd8ir0Ac2+CWyMCSpNIsKYPLYv3dvE8czcjWwuKOZv1/cjuXkTp0trdDYCMMYEHRHh7vPS+fuNmeQVlTJ68iK+3lLkdFmNzgLAGBO0zu/aivcnDqZZk3DGvfIN/1iyNajOC1gAGGOCWqekprx/92DO7ZzErz9Yy6R3VnO0PDjOC1gAGGOCXlxUOC/fkMnE89KZmb2dsVO/Zu+hI06X1eAsAIwxBtclpx+4qAsvXncm63cd5pLJWXy3/YDTZTUoCwBjjKliVK82vHvX2USEhXD135bw9vJ8p0tqMB4FgIiMEJGNIpIrIpNqeD1FRBaIyAoRWSUio9zbE9zbi0Vk8kn2PVtE1tSvG8YY4z3d2sQx++4hZKY254G3VvKbD9dSXlFZ+xv9TK0BICKhwBRgJNAdGCsi3as1exSYpap9gTHAi+7tR4DHgAdOsu+fAcV1K90YYxpO85gI/nHzAG4e3IHXFm3lhleXsq8ksG4y48kIYACQq6pbVLUMmAFcWq2NAnHux/HATgBVLVHVLFxB8CMi0hS4D3iyjrUbY0yDCgsN4deXdOfZq/qQvW0/oydnsX7XIafL8hpPAqAdsL3K83z3tqoeB8aJSD7wCXCPB/v9LfAsUHqqRiIyQUSyRSS7oKDAg90aY4x3XdEvmbduH0R5hfKzFxfz8arAuMmMJwEgNWyr/k2JscA0VU0GRgHTReSk+xaRM4B0VX2vtl+uqlNVNVNVM5OSkjwo1xhjvK9P+2bMvmcw3dvGcfcb33L937/hszW7OObH5wY8CYB8oH2V58m4p3iquAWYBaCqS4AoIPEU+xwE9BORrUAW0FlEvvSsZGOMcUbL2CjevO0sHriwM7l7i7njn98y+I9f8Ozcjew48IPT5Z02qe1rzyISBmwChgM7gGXAtaq6tkqbT4GZqjpNRLoB84F26t65iIwHMlV1Yg37TwM+UtWetRWbmZmp2dnZnvXMGGMaUHlFJV9uLOCNpXks2LgXAYZ1acl1A1MY1qUloSE1TZ44Q0SWq2pm9e21Xg1UVctFZCIwBwgFXlXVtSLyBJCtqrOB+4GXReR/cE0Pja9y8N+K6wRxhIhcBlyoquu81TFjjHFCWGgIF3RvxQXdW5G/v5SZy7YzY9l2bnk9m7bxUYwZkMI1/dvTKi7K6VJPqtYRgC+xEYAxxpcdq6hk/vo9/OubPBbmFBIaIlzQrSXXDkxlaHoiIQ6NCuo8AjDGGOOZ8NAQRvRsw4iebdhaWMKby/J4OzufOWv3kNKiCWMGtOeqfu1Jio10ulTARgDGGNOgjpZXMGftHt74Zhtfb9lHeKhwYY/WXDcwhUEdExBp+FHByUYAFgDGGNNIcvcW8+bSPN5ens/BH47RMTGGawemcMWZyTSPiWiw32sBYIwxPuLIsQo+XrWLN5bmsXzbfiLCQvhprzZcNzCFfqnNvT4qsAAwxhgftGH3Id74Jo/3vt3B4aPldG7VlOsGpnJZ33bER4d75XdYABhjjA8rLSvnw5U7+dc3eazKP0hUeAij+7Tl2oGp9EmOr9eowALAGGP8xOr8g7yxdBsffLeT0rIKerSN47Wb+tMytm7fKbBloMYY4yd6Jcfzh+Te/HJUN97/bicLNxWQ1NT7S0ctAIwxxkfFRoVz/VmpXH9WaoPs324JaYwxQcoCwBhjgpQFgDHGBCkLAGOMCVIWAMYYE6QsAIwxJkhZABhjTJCyADDGmCDlV5eCEJECYFsd354IFHqxHF8SyH2DwO6f9c1/+VP/UlU1qfpGvwqA+hCR7JquhREIArlvENj9s775r0Don00BGWNMkLIAMMaYIBVMATDV6QIaUCD3DQK7f9Y3/+X3/QuacwDGGGN+LJhGAMYYY6qwADDGmCAVEAEgIiNEZKOI5IrIpBpejxSRme7XvxGRtGqvp4hIsYg80Fg1e6o+fROR3iKyRETWishqEanb/eQaSF37JiLhIvK6u0/rReSRxq69Nh707RwR+VZEykXkymqv3SgiOe6fGxuvas/VtX8ickaV/yZXicg1jVt57erzt3O/HiciO0RkcuNUXA+q6tc/QCiwGegIRAArge7V2twF/NX9eAwws9rr7wBvAQ843R9v9Q3X3d5WAX3czxOAUKf75KW+XQvMcD9uAmwF0pzu02n2LQ3oDfwDuLLK9hbAFve/zd2PmzvdJy/2rzOQ4X7cFtgFNHO6T97oW5XXnwfeACY73Z/afgJhBDAAyFXVLapaBswALq3W5lLgdffjt4HhIiIAInIZrv+TrW2kek9Hffp2IbBKVVcCqGqRqlY0Ut2eqE/fFIgRkTAgGigDDjVO2R6ptW+qulVVVwGV1d57EfC5qu5T1f3A58CIxij6NNS5f6q6SVVz3I93AnuBE76h6qD6/O0QkX5AK2BuYxRbX4EQAO2A7VWe57u31dhGVcuBg0CCiMQADwO/aYQ666LOfcP1SUtFZI57uPpQI9R7OurTt7eBElyfHvOAZ1R1X0MXfBo86VtDvLexeKVGERmA61P2Zi/V5Q117puIhADPAg82QF0NIhBuCi81bKu+tvVkbX4D/EVVi90DAl9Tn76FAUOA/kApMF9ElqvqfO+WWGf16dsAoALXFEJzYKGIzFPVLd4tsc486VtDvLex1LtGEWkDTAduVNUTPkk7qD59uwv4RFW3++jx5ASBEAD5QPsqz5OBnSdpk++eNogH9gEDgStF5GmgGVApIkdU1VdO3tSnb/nAV6paCCAinwBnAr4SAPXp27XAZ6p6DNgrIouATFxTeb7Ak76d6r3Dqr33S69U5T316R8iEgd8DDyqql97ubb6qk/fBgFDReQuoCkQISLFqnrCiWRfEQhTQMuADBHpICIRuE4Wzq7WZjZwfDXFlcAX6jJUVdNUNQ14Dvi9Dx38oR59A+YAvUWkifvgeS6wrpHq9kR9+pYHnC8uMcBZwIZGqtsTnvTtZOYAF4pIcxFpjutczpwGqrOu6tw/d/v3gH+o6lsNWGNd1blvqnqdqqa4jycP4Oqjzx78Af9fBeQ6HjAK2IRrLvFX7m1PAKPdj6NwrfLJBZYCHWvYx+P42Cqg+vYNGIfr5PYa4Gmn++KtvuH6dPWWu2/rgAed7ksd+tYf16fNEqAIWFvlvTe7+5wL3OR0X7zZP/d/k8eA76r8nOF0f7z1t6uyj/H4wSoguxSEMcYEqUCYAjLGGFMHFgDGGBOkLACMMSZIWQAYY0yQsgAwxpggZQFgjDFBygLAGGOC1P8DCZ3zqbXx+AEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt    \n",
    "                    \n",
    "plt.plot(ccc, c_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test this baby out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.895299676697339\n"
     ]
    }
   ],
   "source": [
    "final = LinearSVC(tol=.000001,C=0.07)\n",
    "final.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = [i[1][\"content\"] for i in tweets.iterrows()]\n",
    "rating_list = [i[1][\"rating\"] for i in tweets.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_cleaned = preprocess_reviews(tweets_list)\n",
    "len(twitter_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 138540)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tws = ngram_vectorizer.transform(twitter_cleaned)\n",
    "tws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final.predict(tws[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           0       0\n",
       "1           0       0\n",
       "2           1       1\n",
       "3           0       1\n",
       "4           1       1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": rating_list[:100]}).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "score = 0\n",
    "for i, j in zip(predictions, rating_list):\n",
    "    total += 1\n",
    "    if i == j:\n",
    "        score += 1\n",
    "        \n",
    "print(f\"Accuracy: {score/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model_svc.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final, \"final_model_svc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using trained model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    retrieve_model = joblib.load(\"final_model_svc.pkl\")\n",
    "    print(\"using trained model\")\n",
    "except:\n",
    "    print(\"model not found\")\n",
    "    joblib.dump(final, \"final_model_svc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
