{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Data_cyb.json\", lines = True, orient = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "for i in df[\"annotation\"]:\n",
    "    rating.append(int(i[\"label\"][0]))\n",
    "    \n",
    "df[\"rating\"] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>extras</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0                             Get fucking real dude.   \n",
       "1   She is as dirty as they come  and that crook ...   \n",
       "2   why did you fuck it up. I could do it all day...   \n",
       "3   Dude they dont finish enclosing the fucking s...   \n",
       "4   WTF are you talking about Men? No men thats n...   \n",
       "\n",
       "                      annotation  extras  rating  \n",
       "0  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "1  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "2  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "3  {'notes': '', 'label': ['1']}     NaN       1  \n",
       "4  {'notes': '', 'label': ['1']}     NaN       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>That is someone who does it from their heart. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Absolutely applaud your work to secure freedom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>You'll never learn it till you actually live i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Nothing on the reinstatement of federal Capito...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>Crickets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  rating\n",
       "96   That is someone who does it from their heart. ...       1\n",
       "97   Absolutely applaud your work to secure freedom...       0\n",
       "98   You'll never learn it till you actually live i...       1\n",
       "99   Nothing on the reinstatement of federal Capito...       1\n",
       "100                                           Crickets       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"Test_Twitter_Comments.csv\")\n",
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = df[[\"content\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([new_df1,tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(new_df[\"content\"], new_df[\"rating\"], train_size = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(X)\n",
    "reviews_test_clean = preprocess_reviews(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6799303655807013\n",
      "Accuracy for C=0.05: 0.719224073613529\n",
      "Accuracy for C=0.25: 0.7716985824421786\n",
      "Accuracy for C=0.5: 0.7940810743596121\n",
      "Accuracy for C=1: 0.8104949017657299\n"
     ]
    }
   ],
   "source": [
    "baseline_vectorizer = CountVectorizer(binary=True)\n",
    "baseline_vectorizer.fit(reviews_train_clean)\n",
    "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_baseline, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression, Removal Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6694852026858991\n",
      "Accuracy for C=0.05: 0.715991047003233\n",
      "Accuracy for C=0.25: 0.7684655558318826\n",
      "Accuracy for C=0.5: 0.7831385227555334\n",
      "Accuracy for C=1: 0.8010445162894803\n"
     ]
    }
   ],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(no_stop_words_train)\n",
    "X = cv.transform(no_stop_words_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression, Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6622730664013927\n",
      "Accuracy for C=0.05: 0.7065406615269834\n",
      "Accuracy for C=0.25: 0.763989057448396\n",
      "Accuracy for C=0.5: 0.7846306888833623\n",
      "Accuracy for C=1: 0.8010445162894803\n"
     ]
    }
   ],
   "source": [
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(stemmed_reviews_train)\n",
    "X = cv.transform(stemmed_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression, Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6754538671972147\n",
      "Accuracy for C=0.05: 0.7177319074857\n",
      "Accuracy for C=0.25: 0.7632429743844815\n",
      "Accuracy for C=0.5: 0.7831385227555334\n",
      "Accuracy for C=1: 0.8025366824173091\n"
     ]
    }
   ],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(lemmatized_reviews_train)\n",
    "X = cv.transform(lemmatized_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression, Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6749564784879383\n",
      "Accuracy for C=0.05: 0.7130067147475753\n",
      "Accuracy for C=0.25: 0.7699577219597115\n",
      "Accuracy for C=0.5: 0.7898532703307635\n",
      "Accuracy for C=1: 0.8047749316090524\n"
     ]
    }
   ],
   "source": [
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train_clean)\n",
    "X = wc_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression, N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6903755284755037\n",
      "Accuracy for C=0.05: 0.7712011937329023\n",
      "Accuracy for C=0.25: 0.8418303904501367\n",
      "Accuracy for C=0.5: 0.8535190251181298\n",
      "Accuracy for C=1: 0.8565033573737876\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.720964934095996\n",
      "Accuracy for C=0.05: 0.8139766227306641\n",
      "Accuracy for C=0.25: 0.8642128823675702\n",
      "Accuracy for C=0.5: 0.8694354638149714\n",
      "Accuracy for C=1: 0.8724197960706292\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajkim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7306640139268838\n",
      "Accuracy for C=0.05: 0.8259139517532952\n",
      "Accuracy for C=0.25: 0.8619746331758269\n",
      "Accuracy for C=0.5: 0.8617259388211888\n",
      "Accuracy for C=1: 0.8627207162397413\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, Removal of Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(no_stop_words_train)\n",
    "X = cv.transform(no_stop_words_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(stemmed_reviews_train)\n",
    "X = cv.transform(stemmed_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(lemmatized_reviews_train)\n",
    "X = cv.transform(lemmatized_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train_clean)\n",
    "X = wc_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8142253170853022\n",
      "Accuracy for C=0.05: 0.8642128823675702\n",
      "Accuracy for C=0.25: 0.865456354140761\n",
      "Accuracy for C=0.5: 0.8637154936582939\n",
      "Accuracy for C=1: 0.8589903009201691\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8269087291718478\n",
      "Accuracy for C=0.05: 0.8612285501119125\n",
      "Accuracy for C=0.25: 0.8560059686645113\n",
      "Accuracy for C=0.5: 0.8512807759263865\n",
      "Accuracy for C=1: 0.8463068888336235\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8612285501119125\n",
      "Accuracy for C=0.05: 0.8793832380004973\n",
      "Accuracy for C=0.25: 0.8706789355881621\n",
      "Accuracy for C=0.5: 0.8691867694603332\n",
      "Accuracy for C=1: 0.8624720218851032\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the comparison between the combination of the various vectorization with logistic rergression and SVM, 4-gram vectorization with SVM seemed stablize with the greatest accuracy. We later, however, sought to see if stemming, lemmatization, and/or the removal of stop words would improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, 4-grams, Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.855508579955235\n",
      "Accuracy for C=0.05: 0.8729171847799055\n",
      "Accuracy for C=0.25: 0.865456354140761\n",
      "Accuracy for C=0.5: 0.8609798557572743\n",
      "Accuracy for C=1: 0.8560059686645113\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "ngram_vectorizer.fit(stemmed_reviews_train)\n",
    "X = ngram_vectorizer.transform(stemmed_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, 4-grams, Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8599850783387217\n",
      "Accuracy for C=0.05: 0.8724197960706292\n",
      "Accuracy for C=0.25: 0.8619746331758269\n",
      "Accuracy for C=0.5: 0.8594876896294454\n",
      "Accuracy for C=1: 0.853767719472768\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "ngram_vectorizer.fit(lemmatized_reviews_train)\n",
    "X = ngram_vectorizer.transform(lemmatized_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, 4-grams, Stemming, Removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8353643372295448\n",
      "Accuracy for C=0.05: 0.8627207162397413\n",
      "Accuracy for C=0.25: 0.8594876896294454\n",
      "Accuracy for C=0.5: 0.8540164138274061\n",
      "Accuracy for C=1: 0.8473016662521761\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(stemmed_reviews_train)\n",
    "X = ngram_vectorizer.transform(stemmed_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM, 4-grams, Lemmatization, Removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8216861477244467\n",
      "Accuracy for C=0.05: 0.8607311614026362\n",
      "Accuracy for C=0.25: 0.8505346928624721\n",
      "Accuracy for C=0.5: 0.8468042775428998\n",
      "Accuracy for C=1: 0.8385973638398408\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(lemmatized_reviews_train)\n",
    "X = ngram_vectorizer.transform(lemmatized_reviews_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polishing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.8565033573737876\n",
      "Accuracy for C=0.02: 0.8662024372046755\n",
      "Accuracy for C=0.03: 0.8699328525242477\n",
      "Accuracy for C=0.04: 0.8714250186520766\n",
      "Accuracy for C=0.05: 0.8746580452623726\n",
      "Accuracy for C=0.060000000000000005: 0.8731658791345437\n",
      "Accuracy for C=0.06999999999999999: 0.8729171847799055\n",
      "Accuracy for C=0.08: 0.8729171847799055\n",
      "Accuracy for C=0.09: 0.8734145734891818\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.75)\n",
    "\n",
    "ccc = []\n",
    "c_scores = []\n",
    "\n",
    "for c in np.arange(0.01, 0.1, 0.01):\n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    ccc.append(c)\n",
    "    c_scores.append(accuracy_score(y_val, svm.predict(X_val)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt    \n",
    "                    \n",
    "plt.plot(ccc, c_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model - SVM, 4-grams, C = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test this baby out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9166873911962199\n"
     ]
    }
   ],
   "source": [
    "final = LinearSVC(tol=.000001,C=0.05)\n",
    "final.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
